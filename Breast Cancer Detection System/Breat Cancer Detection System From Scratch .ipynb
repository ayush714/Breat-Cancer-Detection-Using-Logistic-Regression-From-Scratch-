{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<center>\n",
    "    <img src=\"unnamed.png\" width=\"300\" alt=\"Newera logo\"  />\n",
    "</center> \n",
    "\n",
    "This Notebook is Prepared by Ayush Singh, Founder of Newera YT Channel, He had also taught the theory in the video, so I highly recommend to watch that video and then come back and start reading below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a breat cancer detection system\n",
    "\n",
    "In this Notebook, you will build your own breat cancer detection system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification is another supervised learning Approach, In Classification our output value **y** will be in discrete value like 0 or 1.  \n",
    "Below are some examples:- \n",
    "\n",
    " - Classification of Cat or Dog \n",
    " - Prognostic Models  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification has different algorithms, which we will study in detail but for a couple of videos, we will be diving into the one of the most powerful classification algorithms, **Logistic Regression**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression is a classification algorithms, which will tell you the probability that an instance belong to this class or not with some threshold. If our probability is greater than 0.5 or 50 % then we will say this belongs to the class, means positive_label **1** ot if lesser we denote negative class or vice versa **0**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example \n",
    "\n",
    "- What is the probability that this image is cat image? \n",
    "\n",
    "If our probability is above 0.5 which is our threshold, then it is a cat image **1** otherwise it is non cat **0**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fact about Logistic Regression\n",
    "\n",
    "It is called as regression because it's underlying technique is quite the same as Linear Regression. The term ‚ÄúLogistic‚Äù is taken from the Logit function that is used in this method of classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's start diving in logistic regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis Function Or Prediction Function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It does the same work as linear regression does, logistic regression computes the features weights and the bias term and multiply with the respected features and sum them up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\hat{Y} = h(x) =  \\Theta_0*x_{0} + \\Theta_1*x_{1} + \\Theta_2*x_{2} \\ + \\Theta_3*x_{3} + \\Theta_n*x_{n}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vectorized form of above equation** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\hat{Y} = h(x) = (x^T\\Theta)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But one thing more it does, it computes the sigmoid of the hypothesis, which will enable the hypothesis to give output between 0 and 1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\hat{Y} = h(x) =  \\sigma(x^T\\Theta)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's denote $x^T\\Theta$ as z, so we can write our function:- \n",
    "$\\sigma(z)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\sigma(z)$ is a sigmoid function which outputs the number between 0 and 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sigmoid Function Can be Defined as:-**\n",
    "$\\sigma(z) = \\frac{1}{1+exp(-z)}$ \n",
    "\n",
    "$$z = \\theta_0 x_0 + \\theta_1 x_1 + \\theta_2 x_2 + ... \\theta_N x_N$$ \n",
    "\n",
    "\n",
    "It forms S shaped figure."
   ]
  },
  {
   "attachments": {
    "index.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![index.png](attachment:index.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We set the threshold** \n",
    "$\\hat{Y}$ = 0 if prob < 0.5 else 1 if prob > 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Implementing sigmoid**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # for scientific computation \n",
    "import pandas as pd # for working with data\n",
    "from sklearn.model_selection import train_test_split # for splitting the data\n",
    "from sklearn.datasets import load_breast_cancer # dataset that we will be using \n",
    "import warnings # optional \n",
    "warnings.filterwarnings( \"ignore\" ) # optional "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z): \n",
    "    '''\n",
    "    input:  \n",
    "        z : a scalar or an array \n",
    "    output: \n",
    "        h : sigmoid of z \n",
    "    '''\n",
    "    h = 1 / (1 + np.exp(-z))\n",
    "    \n",
    "    return h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost Function For Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loss function for a single training example is\n",
    "$$ J(\\theta) = -1 \\times \\left( y^{(i)}\\log (h(z(\\theta)^{(i)})) + (1-y^{(i)})\\log (1-h(z(\\theta)^{(i)})) \\right)$$ \n",
    "\n",
    "* when the model predicts 1 and the label $y$ is also 1, the loss for that training example is 0. \n",
    "* Similarly, when the model predicts 0 and the actual label is also 0, the loss for that training example is 0. \n",
    "* However, when the model prediction is close to 1and the label is 0, the second term of the log loss becomes a large.\n",
    "\n",
    "\n",
    "***Cost Function for m training examples***\n",
    "\n",
    "$$J(\\theta) = -\\frac{1}{m} \\sum_{i=1}^m y^{(i)}\\log (h(z(\\theta)^{(i)})) + (1-y^{(i)})\\log (1-h(z(\\theta)^{(i)}))$$\n",
    "* $m$ is the number of training examples\n",
    "* $y^{(i)}$ is the actual label of the i-th training example.\n",
    "* $h(z(\\theta)^{(i)})$ is the model's prediction for the i-th training example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent [ Optimization Objective ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To update our weights $\\Theta$ we apply our gradient descent, to improve our weights at every iteration. We take out the partial derviative of our cost function, or in other words, how much the cost function will change if we change $\\Theta$ little bit. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gradient of the cost function $J$ with respect to one of the weights $\\theta_j$ is:\n",
    "\n",
    "\n",
    "$$\\nabla_{\\theta_j}J(\\theta) = \\frac{1}{m} \\sum_{i=1}^m(x^{(i)}-y^{(i)})x_j $$\n",
    "\n",
    "* 'i' is the index across all 'm' training examples.\n",
    "* 'j' is the index of the weight $\\theta_j$, so $x_j$ is the feature associated with weight $\\theta_j$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are taking gradient step to reach to our global minimum, so that's why we are updating our previous theta parameter with the new one.\n",
    "\n",
    "\n",
    "$$\\theta_j = \\theta_j - \\alpha \\times \\nabla_{\\theta_j}J(\\theta) $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Technical Note on $\\alpha$ hyperparameter**\n",
    "\n",
    "\n",
    "You have to tune the learning rate means you have to try different different rates and see your model how it performs. \n",
    "\n",
    "If you choose **very small learning rate**, it will be very very slow and it will never converge to the local minimum.  \n",
    "\n",
    "If you choose **very large learning rate**, your model might diverge and never converge to the local minimum. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guide on implementing vectorized Logistic Regression ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hypothesis Function**\n",
    "\n",
    "**z**= $ X . \\Theta\\$\n",
    "<br>\n",
    "And then you apply the sigmoid to each element in 'z': ‚Ñé(ùëß)=ùë†ùëñùëîùëöùëúùëñùëë(ùëß)\n",
    "\n",
    "- It has dimensions (m,1), where m is no. of training examples.   \n",
    "<br>\n",
    "\n",
    "**Vectorized Cost Function**\n",
    "$$J(\\Theta)= \\frac{-1}{m} \\times \\left(\\mathbf{y}^T \\cdot log(\\mathbf{h}) + \\mathbf{(1-y)}^T \\cdot log(\\mathbf{1-h}) \\right)$$\n",
    "\n",
    "\n",
    "**Vectorized Gradient Descent** \n",
    "<br>\n",
    "Above, we are taking out the gradient and updating  single weight $\\theta_i$ at a time, but it will consume lot of time and space, instead of doing that, we can make a giant vector theta, which will contains all the feature weights, as given below:- \n",
    "\n",
    "$$\\mathbf{\\Theta} = \\begin{pmatrix}\n",
    "\\theta_0\n",
    "\\\\\n",
    "\\theta_1\n",
    "\\\\ \n",
    "\\theta_2 \n",
    "\\\\ \n",
    "\\vdots\n",
    "\\\\ \n",
    "\\theta_n\n",
    "\\end{pmatrix}$$ \n",
    "<br> \n",
    "<br> \n",
    "\n",
    "* The 'logits', 'z', are calculated by multiplying the feature matrix 'x' with the weight vector 'theta'.  $z = \\mathbf{x}\\mathbf{\\theta}$\n",
    "    * $\\mathbf{x}$ has dimensions (m, n+1)  \n",
    "    * $\\mathbf{\\theta}$: has dimensions (n+1, 1)\n",
    "    * $\\mathbf{z}$: has dimensions (m, 1)\n",
    "\n",
    "\n",
    "We have to update our theta values, so it is also vectorized:- \n",
    "\n",
    "$$\\mathbf{\\Theta} = \\mathbf{\\Theta} - \\frac{\\alpha}{m} \\times \\left( \\mathbf{x}^T \\cdot \\left( \\mathbf{h-y} \\right) \\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradientDescent(x, y, theta, alpha, num_iters):\n",
    "    '''\n",
    "    Input:\n",
    "        x: matrix of features which is (m,n+1)\n",
    "        y: corresponding labels of the input matrix x, dimensions (m,1)\n",
    "        theta: weight vector of dimension (n+1,1)\n",
    "        alpha: learning rate\n",
    "        num_iters: number of iterations you want to train your model for\n",
    "    Output:\n",
    "        theta: your final weight vector\n",
    "    '''\n",
    "    m = len(y)\n",
    "    \n",
    "    for i in range(0, num_iters):\n",
    "        \n",
    "        # get z, the dot product of x and theta\n",
    "        z =  np.dot(x, theta) \n",
    "        \n",
    "        # get the sigmoid of z\n",
    "        h = sigmoid(z) \n",
    "        \n",
    "        # calculate the cost function\n",
    "        J = (-1/m) * (np.dot(y.T, np.log(h)) + np.dot((1 - y).T, np.log(1 - h))) \n",
    "\n",
    "        # update the weights theta\n",
    "        theta =  theta -  alpha/m * (np.dot(x.T, (h-y))) \n",
    "        \n",
    "    return theta "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data and Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _breast_cancer_dataset:\n",
      "\n",
      "Breast cancer wisconsin (diagnostic) dataset\n",
      "--------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 569\n",
      "\n",
      "    :Number of Attributes: 30 numeric, predictive attributes and the class\n",
      "\n",
      "    :Attribute Information:\n",
      "        - radius (mean of distances from center to points on the perimeter)\n",
      "        - texture (standard deviation of gray-scale values)\n",
      "        - perimeter\n",
      "        - area\n",
      "        - smoothness (local variation in radius lengths)\n",
      "        - compactness (perimeter^2 / area - 1.0)\n",
      "        - concavity (severity of concave portions of the contour)\n",
      "        - concave points (number of concave portions of the contour)\n",
      "        - symmetry\n",
      "        - fractal dimension (\"coastline approximation\" - 1)\n",
      "\n",
      "        The mean, standard error, and \"worst\" or largest (mean of the three\n",
      "        worst/largest values) of these features were computed for each image,\n",
      "        resulting in 30 features.  For instance, field 0 is Mean Radius, field\n",
      "        10 is Radius SE, field 20 is Worst Radius.\n",
      "\n",
      "        - class:\n",
      "                - WDBC-Malignant\n",
      "                - WDBC-Benign\n",
      "\n",
      "    :Summary Statistics:\n",
      "\n",
      "    ===================================== ====== ======\n",
      "                                           Min    Max\n",
      "    ===================================== ====== ======\n",
      "    radius (mean):                        6.981  28.11\n",
      "    texture (mean):                       9.71   39.28\n",
      "    perimeter (mean):                     43.79  188.5\n",
      "    area (mean):                          143.5  2501.0\n",
      "    smoothness (mean):                    0.053  0.163\n",
      "    compactness (mean):                   0.019  0.345\n",
      "    concavity (mean):                     0.0    0.427\n",
      "    concave points (mean):                0.0    0.201\n",
      "    symmetry (mean):                      0.106  0.304\n",
      "    fractal dimension (mean):             0.05   0.097\n",
      "    radius (standard error):              0.112  2.873\n",
      "    texture (standard error):             0.36   4.885\n",
      "    perimeter (standard error):           0.757  21.98\n",
      "    area (standard error):                6.802  542.2\n",
      "    smoothness (standard error):          0.002  0.031\n",
      "    compactness (standard error):         0.002  0.135\n",
      "    concavity (standard error):           0.0    0.396\n",
      "    concave points (standard error):      0.0    0.053\n",
      "    symmetry (standard error):            0.008  0.079\n",
      "    fractal dimension (standard error):   0.001  0.03\n",
      "    radius (worst):                       7.93   36.04\n",
      "    texture (worst):                      12.02  49.54\n",
      "    perimeter (worst):                    50.41  251.2\n",
      "    area (worst):                         185.2  4254.0\n",
      "    smoothness (worst):                   0.071  0.223\n",
      "    compactness (worst):                  0.027  1.058\n",
      "    concavity (worst):                    0.0    1.252\n",
      "    concave points (worst):               0.0    0.291\n",
      "    symmetry (worst):                     0.156  0.664\n",
      "    fractal dimension (worst):            0.055  0.208\n",
      "    ===================================== ====== ======\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Class Distribution: 212 - Malignant, 357 - Benign\n",
      "\n",
      "    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n",
      "\n",
      "    :Donor: Nick Street\n",
      "\n",
      "    :Date: November, 1995\n",
      "\n",
      "This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\n",
      "https://goo.gl/U2Uwz2\n",
      "\n",
      "Features are computed from a digitized image of a fine needle\n",
      "aspirate (FNA) of a breast mass.  They describe\n",
      "characteristics of the cell nuclei present in the image.\n",
      "\n",
      "Separating plane described above was obtained using\n",
      "Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\n",
      "Construction Via Linear Programming.\" Proceedings of the 4th\n",
      "Midwest Artificial Intelligence and Cognitive Science Society,\n",
      "pp. 97-101, 1992], a classification method which uses linear\n",
      "programming to construct a decision tree.  Relevant features\n",
      "were selected using an exhaustive search in the space of 1-4\n",
      "features and 1-3 separating planes.\n",
      "\n",
      "The actual linear program used to obtain the separating plane\n",
      "in the 3-dimensional space is that described in:\n",
      "[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\n",
      "Programming Discrimination of Two Linearly Inseparable Sets\",\n",
      "Optimization Methods and Software 1, 1992, 23-34].\n",
      "\n",
      "This database is also available through the UW CS ftp server:\n",
      "\n",
      "ftp ftp.cs.wisc.edu\n",
      "cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \n",
      "     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \n",
      "     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\n",
      "     San Jose, CA, 1993.\n",
      "   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \n",
      "     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \n",
      "     July-August 1995.\n",
      "   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\n",
      "     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \n",
      "     163-171.\n"
     ]
    }
   ],
   "source": [
    "data = load_breast_cancer()  \n",
    "print(data.DESCR)\n",
    "\n",
    "X = data.data  \n",
    "y = data.target \n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,y,test_size = 0.3, random_state=0 ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The resulting vector of weights is [0.26710018, 0.42972718, 1.5782131, 0.98107781, 0.00252358, -0.0004329, -0.00379412, -0.00170445, 0.00473013, 0.00200138, 0.00016844, 0.03043851, -0.01000972, -0.79385023, 0.00017963, 5.59e-06, -0.00018409, 2.707e-05, 0.00048862, 6.335e-05, 0.27866735, 0.544369, 1.58675777, -1.15944894, 0.0032222, -0.00251253, -0.00721919, -0.00171032, 0.00677563, 0.00202829]\n"
     ]
    }
   ],
   "source": [
    "### Now, we will train our model with gradient descent ### \n",
    "theta = gradientDescent(X_train, Y_train, np.zeros((30)), 0.001, 700)\n",
    "print(f\"The resulting vector of weights is {[round(t, 8) for t in np.squeeze(theta)]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see above, the you got the feature weights of all the features. Now using that you will make predictions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing our model ### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictions(X, theta): \n",
    "    '''\n",
    "    input: \n",
    "        X : input  \n",
    "        theta : feature weights \n",
    "    output: \n",
    "        Y : 0 Or 1 \n",
    "    '''\n",
    "    Z = 1 / ( 1 + np.exp( - ( X.dot( theta )) ) )        \n",
    "    Y = np.where( Z > 0.5, 1, 0 )        \n",
    "    return Y\n",
    "\n",
    "y_pred = predictions(X_test, theta) ### Predicting on the test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_logistic_regression(test_x, test_y, theta):\n",
    "    y_hat = [] # making an empty list \n",
    "    for x in test_x:\n",
    "        # get the label prediction \n",
    "        y_pred = predictions(x, theta) \n",
    "        \n",
    "        if y_pred > 0.5:\n",
    "            # append 1.0 to the list\n",
    "            y_hat.append(1)\n",
    "        else:\n",
    "            # append 0 to the list\n",
    "            y_hat.append(0)\n",
    "    accuracy = (y_hat==np.squeeze(test_y)).sum()/len(test_x)\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression model's accuracy = 0.9298\n"
     ]
    }
   ],
   "source": [
    "accuracy = test_logistic_regression(X_test, Y_test, theta)\n",
    "print(f\"Logistic regression model's accuracy = {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Congratulations üòäüòä  \n",
    "\n",
    "You have developed your own end to end logistic regression model that can predict, whether the person has cancer or not, and even you haven't use any kind of external library for training. And also you have mastered logistic regression. \n",
    "<br>  \n",
    "\n",
    "If you had completed this assignment, you have got both theoretical and practical knowledge, of one of the most popular algorithm **Logistic Regression**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are liking my effort, you can conider subscribing my youtube channel, and also following me on github, instagram and linkedin.  \n",
    "\n",
    "Youtube:-  https://www.youtube.com/c/neweraa \n",
    "<br>\n",
    "Linkedin:- https://www.linkedin.com/in/ayush-singh488/\n",
    "<br>\n",
    "instagram:- https://www.instagram.com/intelligentprogrammer123/  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
